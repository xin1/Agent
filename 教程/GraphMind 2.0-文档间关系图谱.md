æ›´æ–°  
```
ValueError: Input length of input_ids is 14317, but `max_length` is set to 8192. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`
AttributeError: 'ChatGLMForConditionalGeneration' object has no attribute '_extract_past_from_model_output'
Traceback (most recent call last):
  File "d:\Gradio\code\Graph_Mind\document_graph_project\run.py", line 6, in <module>
    pdf_texts = load_all_pdfs("data/pdfs")
  File "d:\Gradio\code\Graph_Mind\document_graph_project\app\extract_text.py", line 13, in load_all_pdfs
    texts[fname] = extract_text_from_pdf(full_path)
  File "d:\Gradio\code\Graph_Mind\document_graph_project\app\extract_text.py", line 5, in extract_text_from_pdf
    doc = fitz.open(pdf_path)
AttributeError: module 'fitz' has no attribute 'open'
```
ä½ çš„é”™è¯¯æ˜¯å› ä¸ºåœ¨ `app.analyze_docs` æ¨¡å—ä¸­æ²¡æœ‰å®šä¹‰åä¸º `parse_summary_and_labels` çš„å‡½æ•°ï¼Œä½†ä½ åœ¨ `run.py` ä¸­å°è¯•å¯¼å…¥å®ƒã€‚ä¸‹é¢æ˜¯è§£å†³æ–¹æ¡ˆå’Œå»ºè®®çš„æ ‡å‡†é¡¹ç›®ç»“æ„ã€‚

---

## âœ… æ”¹è¿›å»ºè®®ä¸é¡¹ç›®ç»“æ„

æˆ‘ä»¬è¦æ„å»ºçš„å®Œæ•´æµç¨‹ï¼š

1. **æå– PDF æ–‡æœ¬**ï¼ˆextract\_text.pyï¼‰
2. **ç”¨å¤§æ¨¡å‹æ‘˜è¦å’Œæ‰“æ ‡ç­¾**ï¼ˆanalyze\_docs.pyï¼‰
3. **è§£ææ‘˜è¦ä¸æ ‡ç­¾**ï¼ˆæ–°å¢ï¼šparse\_summary\_and\_labelså‡½æ•°ï¼‰
4. **æ„å»ºæ–‡æ¡£å…³ç³»å›¾è°±**ï¼ˆbuild\_graph.pyï¼‰
5. **å¯¼å‡º Dify å¯è¯»æ ¼å¼**ï¼ˆexport\_dify.pyï¼‰
6. **å¯é€‰ï¼šGradio æˆ– Streamlit å‰ç«¯äº¤äº’**ï¼ˆåç»­å¯æ·»åŠ ï¼‰

---

## âœ… ä¿®å¤æ–¹æ¡ˆä¸å®Œæ•´ä»£ç 

### ğŸ”§ 1. `analyze_docs.py` ç¤ºä¾‹

```python
from transformers import AutoTokenizer, AutoModel
import torch

# åŠ è½½ ChatGLM3 æ¨¡å‹ï¼ˆæœ¬åœ°éƒ¨ç½²ï¼Œå»ºè®®ä½¿ç”¨ GPUï¼‰
tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True).half().cuda()
model.eval()

# è®¾ç½®æœ€å¤§ tokens é•¿åº¦ï¼ˆChatGLM3 æ”¯æŒ 8192ï¼‰
MAX_TOKENS = 8192

def truncate_text_by_tokens(text, tokenizer, max_tokens=MAX_TOKENS - 512):
    """æŒ‰ tokens æˆªæ–­æ–‡æœ¬ï¼Œç¡®ä¿è¾“å…¥ä¸è¶…é•¿"""
    tokens = tokenizer.tokenize(text)
    if len(tokens) > max_tokens:
        tokens = tokens[:max_tokens]
    truncated_text = tokenizer.convert_tokens_to_string(tokens)
    return truncated_text

def summarize_and_tag(text):
    """ä¼ å…¥åŸå§‹æ–‡æœ¬ï¼Œè¾“å‡º ChatGLM çš„æ€»ç»“å’Œæ ‡ç­¾å“åº”"""
    text = truncate_text_by_tokens(text, tokenizer)

    prompt = f"""è¯·é˜…è¯»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¹¶æ€»ç»“è¦ç‚¹ï¼Œç»™å‡º3-5ä¸ªæ ‡ç­¾ï¼Œç”¨ã€æ€»ç»“ã€‘å’Œã€æ ‡ç­¾ã€‘æ ‡æ³¨è¾“å‡ºï¼š
{text}
"""
    response, _ = model.chat(tokenizer, prompt, history=[])
    return response

def parse_summary_and_labels(text):
    """è§£ææ¨¡å‹è¾“å‡ºä¸­çš„æ€»ç»“ä¸æ ‡ç­¾"""
    summary = ""
    tags = []
    if "ã€æ€»ç»“ã€‘" in text and "ã€æ ‡ç­¾ã€‘" in text:
        summary = text.split("ã€æ€»ç»“ã€‘")[1].split("ã€æ ‡ç­¾ã€‘")[0].strip()
        tag_text = text.split("ã€æ ‡ç­¾ã€‘")[1].strip()
        tags = [t.strip("ï¼Œ,ã€") for t in tag_text.replace("\n", " ").split() if t.strip()]
    return summary, tags

```

---

### âœ… 2. run.py ç¤ºä¾‹ï¼ˆæ•´ä½“è°ƒåº¦ï¼‰

```python
from app.extract_text import load_all_pdfs
from app.analyze_docs import summarize_and_tag, parse_summary_and_labels
from app.build_graph import build_doc_graph
from app.export_dify import export_to_dify_format

pdf_texts = load_all_pdfs("data/pdfs")
doc_infos = {}

for fname, text in pdf_texts.items():
    raw = summarize_and_tag(text)
    summary, tags = parse_summary_and_labels(raw)
    doc_infos[fname] = {"summary": summary, "tags": tags}

build_doc_graph(doc_infos)
export_to_dify_format(doc_infos)
```

---

### âœ… 3. extract\_text.py

```python
import fitz  # PyMuPDF
import os

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    return "\n".join([page.get_text() for page in doc])

def load_all_pdfs(folder):
    texts = {}
    for fname in os.listdir(folder):
        if fname.endswith(".pdf"):
            full_path = os.path.join(folder, fname)
            texts[fname] = extract_text_from_pdf(full_path)
    return texts
```

---

### âœ… 4. é¡¹ç›®ç»“æ„å»ºè®®

```
document_graph_project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract_text.py
â”‚   â”œâ”€â”€ analyze_docs.py
â”‚   â”œâ”€â”€ build_graph.py
â”‚   â”œâ”€â”€ export_dify.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/
â”œâ”€â”€ output/
â”‚   â””â”€â”€ doc_graph.html
â”œâ”€â”€ run.py
```

---

## ğŸ’¡ æ³¨æ„äº‹é¡¹

* ä½¿ç”¨ `chatglm3-6b` æ¨¡å‹è¯·ç¡®ä¿ç¯å¢ƒä¸­æ”¯æŒ FP16/GPU æ¨ç†ã€‚
* å¦‚æœæ¨¡å‹å¤ªå¤§ï¼Œå¯ä»¥ä½¿ç”¨ `bge-large-zh`, `text2vec`, æˆ–å…¶å®ƒè½»é‡æ¨¡å‹+å‘é‡åŒ¹é…ã€‚
* å¯é€‰åŠ å…¥ Gradio åšå¯è§†åŒ–ç•Œé¢ã€‚

---

æ˜¯å¦éœ€è¦æˆ‘ç»§ç»­æä¾› `build_graph.py`ï¼ˆç”Ÿæˆäº¤äº’å¼ç½‘é¡µå›¾è°±ï¼‰å’Œ `export_dify.py`ï¼ˆå¯¼å‡ºä¸ºDifyæ ¼å¼ï¼‰ç¤ºä¾‹ä»£ç ï¼Ÿæˆ‘å¯ä»¥ç»§ç»­æ•´ç†è¡¥å……ã€‚

é”™è¯¯
```
ModuleNotFoundError: No module named 'frontend'
File "D:\Gradio\code\Graph_Mind\document_graph_project\app\extract_text.py", line 1, in <module>
    import fitz  # PyMuPDF
  File "D:\Gradio\code\.venv\lib\site-packages\fitz\__init__.py", line 1, in <module>
    from frontend import *
ModuleNotFoundError: No module named 'frontend'

Traceback (most recent call last):
  File "d:\Gradio\code\Graph_Mind\document_graph_project\run.py", line 2, in <module>
    from app.analyze_docs import summarize_and_tag, parse_summary_and_labels
ImportError: cannot import name 'parse_summary_and_labels' from 'app.analyze_docs' (d:\Gradio\code\Graph_Mind\document_graph_project\app\analyze_docs.py)
```
å¥½çš„ï¼Œä»¥ä¸‹æ˜¯åŸºäºæœ¬åœ°å¤§æ¨¡å‹ï¼ˆå¦‚ [ChatGLM3](https://github.com/THUDM/ChatGLM3)ï¼‰åˆ†æå¤šä¸ª PDF æ–‡æ¡£ã€ç”Ÿæˆæ–‡æ¡£æ ‡ç­¾ä¸å…³ç³»å›¾è°±ï¼Œå¹¶å¯¼å‡ºä¸º Dify å¯è¯»æ ¼å¼çš„å®Œæ•´å¼€å‘æµç¨‹å’Œå‚è€ƒä»£ç æ¡†æ¶ï¼š

---

## ğŸ§  é¡¹ç›®ç›®æ ‡

æ„å»ºä¸€ä¸ªå¯éƒ¨ç½²çš„æœ¬åœ°ç³»ç»Ÿï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **è§£æå¤šä¸ª PDF æ–‡æ¡£**ã€‚
2. **è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹æŠ½å–æ¯ç¯‡æ–‡æ¡£çš„å…³é”®ä¿¡æ¯ä¸æ ‡ç­¾**ã€‚
3. **åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§ã€æ ‡ç­¾ã€å†…å®¹ç­‰åˆ†ææ–‡æ¡£é—´çš„å…³ç³»ï¼ˆå¦‚åŒä¸€å…¬å¸ã€ç›¸ä¼¼ä¸»é¢˜ï¼‰**ã€‚
4. **ç”Ÿæˆäº¤äº’å¼çŸ¥è¯†å›¾è°±**ï¼ˆç½‘é¡µå¯è§†åŒ–ï¼Œæ‚¬åœæŸ¥çœ‹æ‘˜è¦ï¼Œæ”¯æŒæ”¾ç¼©/æ‹–åŠ¨ï¼‰ã€‚
5. **å¯¼å‡º Dify å¯è¯»çš„çŸ¥è¯†åº“æ ¼å¼ï¼ˆMarkdown + metadataï¼‰**ã€‚

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
document_graph_project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/                    # å­˜æ”¾å¾…å¤„ç† PDF
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ html_graph/              # ç”Ÿæˆçš„çŸ¥è¯†å›¾è°±ç½‘é¡µ
â”‚   â””â”€â”€ dify_knowledge_base/     # Dify æ ¼å¼çš„è¾“å‡º
â”œâ”€â”€ models/
â”‚   â””â”€â”€ chatglm3/                # ä¸‹è½½çš„æœ¬åœ°æ¨¡å‹
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ extract_text.py          # PDF æ–‡å­—æŠ½å–æ¨¡å—
â”‚   â”œâ”€â”€ analyze_docs.py          # å¤§æ¨¡å‹åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ build_graph.py           # å›¾è°±ç”Ÿæˆä¸å¯è§†åŒ–æ¨¡å—
â”‚   â””â”€â”€ export_dify.py           # Dify æ ¼å¼å¯¼å‡ºæ¨¡å—
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.py                       # ä¸»æµç¨‹å…¥å£
```

---

## ğŸ”§ å¼€å‘æ­¥éª¤ä¸ä»£ç æ¦‚è§ˆ

### 1ï¸âƒ£ PDF æ–‡æœ¬æŠ½å–ï¼ˆ`extract_text.py`ï¼‰

```python
import fitz  # PyMuPDF
import os

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    return "\n".join([page.get_text() for page in doc])

def load_all_pdfs(folder):
    texts = {}
    for fname in os.listdir(folder):
        if fname.endswith(".pdf"):
            full_path = os.path.join(folder, fname)
            texts[fname] = extract_text_from_pdf(full_path)
    return texts
```

---

### 2ï¸âƒ£ æœ¬åœ°æ¨¡å‹è°ƒç”¨ä¸æ ‡ç­¾åˆ†æï¼ˆ`analyze_docs.py`ï¼‰

ä½¿ç”¨ [ChatGLM3](https://github.com/THUDM/ChatGLM3) æœ¬åœ°è¿è¡Œï¼Œæ¨èä½¿ç”¨ Transformers æ¨ç†æ¥å£æˆ–å®˜æ–¹ WebUI API æ¨¡å¼ã€‚

```python
from transformers import AutoTokenizer, AutoModel
import torch

tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True).half().cuda()
model.eval()

def summarize_and_tag(doc_text):
    prompt = f"""
è¯·é˜…è¯»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæç‚¼å…³é”®ä¿¡æ¯ï¼Œå¹¶ä¸ºå…¶æ‰“ä¸Šåˆé€‚çš„æ ‡ç­¾ï¼š
æ–‡æ¡£å†…å®¹å¦‚ä¸‹ï¼š
{doc_text[:2000]}  # æˆªæ–­é˜²æ­¢æº¢å‡º
è¾“å‡ºæ ¼å¼ï¼š
æ–‡æ¡£æ‘˜è¦ï¼š
æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼š
"""
    response, _ = model.chat(tokenizer, prompt, history=[])
    return response
```

---

### 3ï¸âƒ£ åˆ†ææ–‡æ¡£å…³ç³»ï¼ˆæ„å»ºå›¾è°±è¾¹ï¼Œ`build_graph.py`ï¼‰

```python
from pyvis.network import Network

def parse_summary_and_labels(raw_response):
    summary = ""
    tags = []
    for line in raw_response.splitlines():
        if line.startswith("æ–‡æ¡£æ‘˜è¦"):
            summary = line.split("ï¼š", 1)[-1].strip()
        elif line.startswith("æ ‡ç­¾"):
            tags = line.split("ï¼š", 1)[-1].split("ï¼Œ")
    return summary, [t.strip() for t in tags]

def build_doc_graph(doc_infos, output_path="outputs/html_graph/index.html"):
    net = Network(height="750px", width="100%", directed=True)
    tag_map = {}

    for fname, info in doc_infos.items():
        net.add_node(fname, label=fname, title=info['summary'])
        for tag in info['tags']:
            tag_node = f"æ ‡ç­¾:{tag}"
            tag_map.setdefault(tag_node, []).append(fname)
            net.add_node(tag_node, label=tag_node, color='orange')
            net.add_edge(tag_node, fname)

    # ç”Ÿæˆâ€œç›¸ä¼¼æ ‡ç­¾â€å…³ç³»
    for tag, files in tag_map.items():
        for i in range(len(files)):
            for j in range(i + 1, len(files)):
                net.add_edge(files[i], files[j], label="åŒæ ‡ç­¾")

    net.show(output_path)
```

---

### 4ï¸âƒ£ å¯¼å‡ºä¸º Dify å¯è¯»æ ¼å¼ï¼ˆ`export_dify.py`ï¼‰

```python
import os
import json

def export_to_dify_format(doc_infos, output_folder="outputs/dify_knowledge_base"):
    os.makedirs(output_folder, exist_ok=True)
    for fname, info in doc_infos.items():
        data = {
            "metadata": {
                "source": fname,
                "tags": info['tags'],
            },
            "content": info['summary']
        }
        out_path = os.path.join(output_folder, f"{fname}.json")
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
```

---

### 5ï¸âƒ£ ä¸»æµç¨‹ï¼ˆ`run.py`ï¼‰

```python
from app.extract_text import load_all_pdfs
from app.analyze_docs import summarize_and_tag, parse_summary_and_labels
from app.build_graph import build_doc_graph
from app.export_dify import export_to_dify_format

pdf_texts = load_all_pdfs("data/pdfs")
doc_infos = {}

for fname, text in pdf_texts.items():
    raw = summarize_and_tag(text)
    summary, tags = parse_summary_and_labels(raw)
    doc_infos[fname] = {"summary": summary, "tags": tags}

build_doc_graph(doc_infos)
export_to_dify_format(doc_infos)
```

---

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

`requirements.txt` å†…å®¹ï¼š

```text
transformers
torch
pyvis
fitz  # pymupdf
```

---

## ğŸ“ è¡¥å……è¯´æ˜

* **ä½¿ç”¨ GPU åŠ é€Ÿ**ï¼šç¡®ä¿ `torch.cuda.is_available()` è¿”å› Trueã€‚
* **ç”Ÿæˆå›¾è°±äº¤äº’é¡µé¢**ï¼špyvis å¯ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ `html_graph/index.html`ã€‚
* **Dify å…¼å®¹**ï¼šè¾“å‡ºçš„ `json` æ ¼å¼å¯ä½œä¸ºæ–‡æ¡£ä¸Šä¼ è‡³ Dify çš„â€œçŸ¥è¯†åº“â€æ¨¡å—ã€‚
* **æ¨¡å‹æ›¿ä»£å»ºè®®**ï¼šå¦‚éœ€è½»é‡åŒ–æ¨¡å‹ï¼Œå¯æ›¿æ¢ä¸º MiniCPMã€Yi-1.5ã€Mistral-Chinese ç­‰ã€‚

---

æ˜¯å¦éœ€è¦æˆ‘ä¸ºä½ æ‰“åŒ…ä¸ºå¯éƒ¨ç½²çš„ Docker é¡¹ç›®ï¼Ÿæˆ–åŠ ä¸€ä¸ªç®€å•ç½‘é¡µä¸Šä¼ é¡µé¢ï¼Ÿ
