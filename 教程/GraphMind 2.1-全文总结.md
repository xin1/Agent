# GraphMind 2.1-å…¨æ–‡æ€»ç»“
ä¸Šç¯‡æ–‡æ¡£è¿ç”¨åˆ†æ®µå¤„ç†æ–‡æ¡£ï¼Œæˆ‘æƒ³ä¸€æ¬¡æ€§è¿›è¡Œæ€»ç»“ï¼Œå½“å‰æœ‰ **2 ä¸ªå¯ç”¨ GPU**ï¼ˆæ˜¾å­˜åˆ†åˆ«ä¸º 24GB å’Œ 12GBï¼‰  

---

## âœ… ä¸€æ¬¡ä¿®æ”¹ï¼š

### âœ… ç›®æ ‡ï¼š 
ç›®æ ‡ 1ï¼šå°†â€œåˆ†æ®µæ€»ç»“â€ä¿®æ”¹ä¸ºâ€œå…¨æ–‡æ€»ç»“â€   
åˆ é™¤ `chunk_text` å’Œæ®µè½å¾ªç¯ï¼Œç›´æ¥å¯¹å…¨æ–‡æ„é€  promptã€‚  
ç›®æ ‡ 2ï¼šæ”¯æŒå¤šæ–‡æ¡£å¤„ç†æ—¶é¿å…æ˜¾å­˜çˆ†ç‚¸  
æ·»åŠ è‡ªåŠ¨æ£€æµ‹æ˜¾å­˜æ˜¯å¦çˆ†ç‚¸ã€‚  
å¦‚æœå¤±è´¥ï¼ˆçˆ†æ˜¾å­˜ï¼‰ï¼Œå°±åˆ‡æ¢ä¸ºä¸²è¡Œæ–¹å¼å¤„ç†ã€‚  

---

### âœ… ä¿®æ”¹åä»£ç ï¼ˆå…³é”®æ–‡ä»¶ `analyze_docs.py` å’Œ `run.py`ï¼‰

#### ğŸ”§ `app/analyze_docs.py`ï¼ˆé‡æ„ä¸ºå…¨æ–‡æ€»ç»“ï¼Œå¼‚å¸¸å¤„ç†ï¼‰

```python
from transformers import AutoTokenizer, AutoModel
import torch
import re

# åˆå§‹åŒ–æ¨¡å‹
def init_model(gpu_id=0):
    device = f"cuda:{gpu_id}" if torch.cuda.is_available() else "cpu"
    tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True)
    model = AutoModel.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True) \
        .half().to(device).eval()
    return tokenizer, model, device

# å•ä¸ªæ–‡æ¡£çš„å¤„ç†å‡½æ•°ï¼ˆå…¨æ–‡æ€»ç»“ï¼‰
def summarize_and_tag_single(args):
    fname, text, gpu_id = args
    tokenizer, model, device = init_model(gpu_id)
    try:
        prompt = (
            "è¯·ä½ ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œå¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œæ‘˜è¦å’Œæ ‡ç­¾æå–ã€‚\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š\n"
            "ã€æ€»ç»“ã€‘è¿™é‡Œæ˜¯æ•´ç¯‡æ–‡æ¡£çš„æ€»ç»“å†…å®¹\n"
            "ã€æ ‡ç­¾ã€‘æ ‡ç­¾1ã€æ ‡ç­¾2ã€æ ‡ç­¾3\n\n"
            f"æ–‡æ¡£å†…å®¹ï¼š\n{text}"
        )
        response, _ = model.chat(tokenizer, prompt, history=[], max_new_tokens=2048)
        return fname, response
    except RuntimeError as e:
        if "out of memory" in str(e):
            print(f"[è­¦å‘Š] GPU {gpu_id} æ˜¾å­˜ä¸è¶³ï¼š{fname} æ”¹ä¸º CPU ä¸²è¡Œå¤„ç†")
        raise e  # ç”±å¤–å±‚æ•è·
    except Exception as e:
        print(f"[é”™è¯¯] å¤„ç†æ–‡æ¡£ {fname} æ—¶å¼‚å¸¸ï¼š{str(e)}")
        return fname, ""

# è§£ææ¨¡å‹è¾“å‡º
def parse_summary_and_labels(raw_text):
    summary_match = re.search(r"ã€æ€»ç»“ã€‘(.*?)ã€æ ‡ç­¾ã€‘", raw_text, re.S)
    tags_match = re.search(r"ã€æ ‡ç­¾ã€‘(.*)", raw_text, re.S)

    summary = summary_match.group(1).strip() if summary_match else ""
    tag_line = tags_match.group(1).strip() if tags_match else ""
    tags = [t.strip() for t in re.split(r"[ã€,ï¼Œ\s]+", tag_line) if t.strip()]
    return summary, list(set(tags))
```

---

#### ğŸ”§ `run.py`ï¼ˆåŠ å…¥è‡ªåŠ¨ä¸²è¡Œé™çº§é€»è¾‘ï¼‰

```python
from app.extract_text import load_all_pdfs
from app.analyze_docs import summarize_and_tag_single, parse_summary_and_labels
from app.build_graph import build_doc_graph
from app.export_dify import export_to_dify_format
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
import torch

def safe_process(args):
    try:
        return summarize_and_tag_single(args)
    except RuntimeError as e:
        return None  # æ ‡è®°ä¸ºå¤±è´¥

def main():
    pdf_dir = "data/pdfs"
    docs = load_all_pdfs(pdf_dir)

    gpu_count = max(torch.cuda.device_count(), 1)
    tasks = [(name, text, idx % gpu_count) for idx, (name, text) in enumerate(docs.items())]

    doc_infos = {}

    # ä¼˜å…ˆå°è¯•å¹¶è¡Œå¤„ç†
    print(f"å°è¯•å¹¶è¡Œå¤„ç†æ–‡æ¡£ï¼Œä½¿ç”¨ {gpu_count} ä¸ª GPU ...")
    with ProcessPoolExecutor(max_workers=gpu_count) as executor:
        futures = {executor.submit(safe_process, task): task[0] for task in tasks}
        for future in tqdm(as_completed(futures), total=len(futures), desc="åˆ†ææ–‡æ¡£"):
            result = future.result()
            if result is None:
                continue  # ç¨åä¸²è¡Œé‡è¯•
            fname, raw = result
            summary, tags = parse_summary_and_labels(raw)
            doc_infos[fname] = {"summary": summary, "tags": tags}

    # å¯¹å¤±è´¥çš„æ–‡æ¡£è¿›è¡Œä¸²è¡Œå¤„ç†ï¼ˆé¿å…çˆ†æ˜¾å­˜ï¼‰
    failed = [task for task in tasks if task[0] not in doc_infos]
    if failed:
        print(f"\nä»¥ä¸‹æ–‡æ¡£å°†æ”¹ä¸ºä¸²è¡Œå¤„ç†ï¼ˆå…± {len(failed)} ä¸ªï¼‰ï¼š")
        for fname, _, _ in failed:
            print(f"  - {fname}")
        for fname, text, _ in tqdm(failed, desc="ä¸²è¡Œå¤„ç†"):
            try:
                raw = summarize_and_tag_single((fname, text, 0))[1]
                summary, tags = parse_summary_and_labels(raw)
                doc_infos[fname] = {"summary": summary, "tags": tags}
            except Exception as e:
                print(f"[å¤±è´¥] æ–‡æ¡£ {fname} æ— æ³•å¤„ç†ï¼š{str(e)}")

    # æ„å»ºå›¾è°± + å¯¼å‡º
    build_doc_graph(doc_infos)
    export_to_dify_format(doc_infos)

if __name__ == "__main__":
    main()
```

---

### âœ… æ•´ä½“ä¼˜åŠ¿

| ç‰¹æ€§          | å®ç°                |
| ----------- | ----------------- |
| å…¨æ–‡æ€»ç»“        | æ›¿æ¢æ®µè½åˆ†å‰²ä¸ºå…¨æ–‡ prompt  |
| GPU ä¼˜å…ˆå¹¶è¡Œå¤„ç†  | åˆ©ç”¨å¤š GPU è½®è¯¢è°ƒåº¦      |
| è‡ªåŠ¨é˜²çˆ†æ˜¾å­˜      | å¤±è´¥ååˆ‡æ¢ä¸²è¡Œ + CPU     |
| å¼º Prompt è¾“å‡º | æ¨¡å‹ä¸¥æ ¼è¾“å‡ºã€æ€»ç»“ã€‘å’Œã€æ ‡ç­¾ã€‘æ ¼å¼ |
| è§£æå¥å£®        | å¤šç§åˆ†éš”ç¬¦æ”¯æŒï¼Œé¿å…æå–å¤±è´¥    |

---
